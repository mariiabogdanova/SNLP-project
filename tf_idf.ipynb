{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/esapalosaari/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading English model...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "import stanza\n",
    "print(\"Downloading English model...\")\n",
    "stanza.download('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_normalize(doc_str, stopwords):\n",
    "    \"\"\"Tokenizes, lemmatizes, lowercases and removes stop words.\n",
    "    \n",
    "    this function takes in a path to a song, reads the song file,\n",
    "    tokenizes it into words, then lemmatizes and lowercases these words.\n",
    "    finally, stopwords given to the function are removed from the list of song lemmas\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        a path to a text file\n",
    "    stopwords : list of strings\n",
    "        stopwords that should be removed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    normalized_song : list of strings\n",
    "        a song represented as a list of its lemmas\n",
    "    \"\"\"\n",
    "    \n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize, lemma',  verbose=False)\n",
    "    doc = nlp(doc_str)\n",
    "    words = doc.iter_words()\n",
    "    normalized_doc = []\n",
    "    for w in words:\n",
    "        w = w.lemma.lower()\n",
    "        if not w in stopwords:\n",
    "            normalized_doc.append(w)\n",
    "    normalized_doc = ' '.join(normalized_doc)\n",
    "    return normalized_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the numbers at the start and end of the documents.\n",
    "DATAFILE = \"./Data/LeePincombeWelshDocuments.txt\"\n",
    "CLEANFILE = \"./Data/cleanLPW.txt\"\n",
    "INDIVIDUAL_DOCS = \"./Data/Docs\"\n",
    "stopwords_english = stopwords.words('english')\n",
    "normalized_docs = []\n",
    "if (os.path.exists(CLEANFILE)):\n",
    "    os.remove(CLEANFILE)\n",
    "i = 0\n",
    "with open(DATAFILE, 'r', encoding=\"utf8\", errors=\"ignore\") as inputfile:\n",
    "     lines = inputfile.readlines()\n",
    "     for line in lines[1:-1]:\n",
    "        start_removed = re.sub(\"(\\d*\\.\\s)\", \"\", line, 1)\n",
    "        end_removed = re.sub(\"\\(\\d* words\\)\", \"\", start_removed, 1)\n",
    "        normalized_docs.append(tokenize_and_normalize(end_removed, stopwords_english).split())\n",
    "        with open(CLEANFILE, 'a+') as outputfile:\n",
    "            outputfile.write(end_removed)\n",
    "        with open(INDIVIDUAL_DOCS+f\"/{i}.txt\", \"w+\") as docfile:\n",
    "            docfile.write(end_removed)\n",
    "            i = i + 1\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['national', 'executive', 'strife-torn', 'democrat', 'last', 'night', 'appoint', 'little', '-known', 'west', 'australian', 'senator', 'brian', 'greig', 'interim', 'leader', '-', 'shock', 'move', 'likely', 'provoke', 'conflict', 'party', \"'s\", 'senators', 'organisation', '.', 'move', 'reassert', 'control', 'party', \"'s\", 'seven', 'senators', ',', 'national', 'executive', 'last', 'night', 'reject', 'aden', 'ridgeway', \"'s\", 'bid', 'become', 'interim', 'leader', ',', 'favour', 'senator', 'greig', ',', 'supporter', 'deposed', 'leader', 'natasha', 'stott', 'despoja', 'outspoken', 'gay', 'rights', 'activist', '.', '.'], ['cash-strapped', 'financial', 'service', 'group', 'amp', 'shelved', '$', '400', 'million', 'plan', 'buy', 'share', 'back', 'investor', 'raise', '$', '750', 'million', 'fresh', 'capital', 'profit', 'crashed', 'six', 'month', 'june', '30', '.', 'chief', 'executive', 'paul', 'batchelor', 'say', 'result', '\"', 'solid', '\"', 'describe', 'bad', 'condition', 'stock', 'market', '20', 'year', '.', 'amp', \"'s\", 'half', '-', 'year', 'profit', 'sink', '25', 'per', 'cent', '$', '303', 'million', ',', '27', 'c', 'share', ',', 'australia', \"'s\", 'large', 'investor', 'fund', 'manager', 'fail', 'hit', 'project', '5', 'per', 'cent', 'earnings', 'growth', 'target', 'batter', 'fall', 'return', 'share', 'market', '.', '.'], ['united', 'state', 'government', 'say', 'want', 'see', 'president', 'robert', 'mugabe', 'remove', 'power', 'work', 'zimbabwean', 'opposition', 'bring', 'change', 'administration', '.', 'score', 'white', 'farmer', 'go', 'hide', 'escape', 'round', '-', 'zimbabwean', 'police', ',', 'senior', 'bush', 'administration', 'official', 'call', 'mr', 'mugabe', \"'s\", 'rule', '\"', 'illegitimate', 'irrational', '\"', 'say', 're-election', 'president', 'march', 'win', 'fraud', '.', 'walter', 'kansteiner', ',', 'assistant', 'secretary', 'state', 'african', 'affair', ',', 'go', 'blame', 'mr', 'mugabe', \"'s\", 'policy', 'contribute', 'threat', 'famine', 'zimbabwe', '.', '.'], ['radical', 'armed', 'islamist', 'group', 'tie', 'tehran', 'baghdad', 'help', 'al', '-', 'qaida', 'establish', 'international', 'terrorist', 'training', 'camp', 'northern', 'iraq', ',', 'kurdish', 'official', 'say', '.', 'intelligence', 'officer', 'autonomous', 'kurdish', 'region', 'iraq', 'tell', 'guardian', 'ansar', 'al', '-', 'islam', '(', 'supporter', 'islam', ')', 'group', 'harbour', '150', 'al', '-', 'qaida', 'member', 'string', 'village', 'control', 'along', 'iraq', '-iran', 'border', '.', 'fled', 'afghanistan', 'us', '-', 'lead', 'offensive', ',', 'official', 'patriotic', 'union', 'kurdistan', '(', 'puk', ')', ',', 'control', 'part', 'north-', 'east', 'iraq', ',', 'claim', '\"', 'abnormal', '\"', 'number', 'recruit', 'make', 'way', 'area', 'jordan', ',', 'syria', 'egypt', '.', '.'], ['washington', 'sharply', 'rebuked', 'russia', 'bombing', 'georgian', 'village', ',', 'warning', 'raid', 'violated', 'georgian', 'sovereignty', 'could', 'worsen', 'tension', 'moscow', 'tbilisi', '.', '\"', 'united', 'state', 'regret', 'loss', 'life', 'deplores', 'violation', 'georgia', \"'s\", 'sovereignty', ',', '\"', 'white', 'house', 'spokesman', 'ari', 'fleischer', 'say', '.', 'mr', 'fleischer', 'say', 'us', 'secretary', 'state', 'colin', 'powell', 'deliver', 'message', 'russian', 'counterpart', 'stern', 'language', 'reflect', 'sign', 'souring', 'relation', 'moscow', 'washington', '.', '.'], ['gay', 'former', 'student', 'melbourne', 'christian', 'school', 'take', 'legal', 'action', 'equal', 'opportunity', 'legislation', ',', 'claim', 'school', 'discriminated', 'sexuality', '.', 'tim', ',', '16', ',', 'allege', 'staff', 'member', 'hillcrest', 'christian', 'college', 'berwick', 'tell', '\"', 'devil', '\"', ',', 'constant', 'bullying', 'student', 'prompt', 'principal', 'tell', 'hide', 'sexuality', '.', 'leave', 'school', 'several', 'week', 'ago', 'continue', 'year', '10', 'distance', 'education', 'say', 'homophobic', 'bullies', 'throw', 'rock', 'head', ',', 'spat', ',', 'call', 'name', 'slashed', 'belongings', '.', '.'], ['senior', 'member', 'saudi', 'royal', 'family', 'pay', 'least', '$', '560', 'million', 'osama', 'bin', 'laden', \"'s\", 'terror', 'group', 'taliban', 'agreement', 'force', 'would', 'attack', 'target', 'saudi', 'arabia', ',', 'accord', 'court', 'document', '.', 'paper', ',', 'file', '$', 'us3000', 'billion', '(', '$', '5500', 'billion', ')', 'lawsuit', 'us', ',', 'allege', 'deal', 'make', 'two', 'secret', 'meeting', 'saudi', 'royals', 'leader', 'al', '-', \"qa'ida\", ',', 'include', 'bin', 'laden', '.', 'money', 'enable', 'al', '-', \"qa'ida\", 'fund', 'training', 'camp', 'afghanistan', 'late', 'attend', 'september', '11', 'hijacker', '.', 'disclosures', 'increase', 'tension', 'us', 'saudi', 'arabia', '.', '.'], ['palestinian', 'hire', 'gun', 'abu', 'nidal', ',', 'whose', 'violent', 'death', 'report', 'last', 'week', 'baghdad', ',', 'murder', 'order', 'iraqi', 'president', 'saddam', 'hussein', 'refuse', 'train', 'al', '-', \"qa'ida\", 'fighter', 'base', 'iraq', ',', 'report', 'say', 'yesterday', '.', 'iraqi', 'intelligence', 'chief', 'taher', 'jalil', 'habbush', 'say', 'last', 'wednesday', 'abu', 'nidal', 'shot', 'kill', 'discover', 'live', 'illegally', 'baghdad', 'face', 'interrogation', 'anti-iraqi', 'activity', '.', 'western', 'diplomat', 'believe', 'radical', 'militant', 'kill', 'refuse', 'reactivate', 'international', 'terrorist', 'network', '.', '.'], ['hunan', 'province', 'remain', 'high', 'alert', 'last', 'night', 'thunderstorms', 'threaten', 'exacerbate', 'flood', 'crisis', ',', 'enter', 'fifth', 'day', '108', 'already', 'dead', 'hundred', 'thousand', 'evacuate', '.', 'flood', 'frontline', 'dongting', 'lake', ',', 'water', 'level', 'peaked', '35', 'saturday', 'night', ',', 'eased', '3', 'cm', 'day', 'hot', 'sun', ',', 'temperature', 'reach', '35c', '.', 'lake', 'still', 'brim', 'dangerously', 'high', 'level', ',', 'spilling', 'top', 'bank', 'place', ',', 'local', 'fearful', 'thunderstorm', 'high', 'wind', 'forecast', 'hit', 'region', 'last', 'night', 'would', 'damage', 'dikes', '.', '1800', 'kilometer', 'dikes', 'around', 'lake', 'stand', '10', 'million', 'people', 'surround', 'farmland', 'disaster', '.', '.'], ['u.s.', '-', 'british', 'air', 'raid', 'southern', 'iraq', 'leave', 'eight', 'civilian', 'dead', 'nine', 'wounded', ',', 'iraqi', 'military', 'say', 'sunday', '.', 'military', 'tell', 'official', 'iraqi', 'news', 'agency', 'warplanes', 'bombed', 'area', 'basra', 'province', ',', '330', 'mile', 'south', 'baghdad', '.', 'u.s.', 'central', 'command', 'florida', 'say', 'coalition', 'aircraft', 'use', 'precision', '-', 'guide', 'weapon', 'strike', 'two', 'air', 'defense', 'radar', 'system', 'near', 'basra', '\"', 'response', 'recent', 'iraqi', 'hostile', 'act', 'coalition', 'aircraft', 'monitoring', 'southern', '-', 'fly', 'zone', '.', '\"', '.'], ['iraq', 'russia', 'close', 'signing', '$', '40', 'billion', 'economic', 'cooperation', 'plan', ',', 'iraq', \"'s\", 'ambassador', 'say', 'saturday', ',', 'deal', 'could', 'put', 'moscow', 'odd', 'united', 'state', 'consider', 'military', 'attack', 'baghdad', '.', 'statement', 'ambassador', 'abbas', 'khalaf', 'come', 'amid', 'indications', 'russia', ',', 'despite', 'strong', 'support', 'post', '-', 'sept', '.', '11', 'antiterrorism', 'coalition', ',', 'maintain', 'improve', 'tie', 'iran', 'north', 'korea', ',', 'together', 'iraq', 'country', 'president', 'bush', 'label', '\"', 'axis', 'evil', '.', '\"', '.'], ['u.s.', 'intelligence', 'cannot', 'say', 'conclusively', 'saddam', 'hussein', 'weapon', 'mass', 'destruction', ',', 'information', 'gap', 'complicating', 'white', 'house', 'effort', 'build', 'support', 'attack', 'saddam', \"'s\", 'iraqi', 'regime', '.', 'cia', 'advise', 'top', 'administration', 'official', 'assume', 'iraq', 'weapon', 'mass', 'destruction', '.', 'agency', 'give', 'president', 'bush', '\"', 'smoking', 'gun', ',', '\"', 'accord', 'u.s.', 'intelligence', 'administration', 'official', '.', '.'], ['drug', 'squad', 'detective', 'ask', 'police', 'ombudsman', 'investigate', 'taskforce', 'examine', 'allegation', 'widespread', 'corruption', 'within', 'squad', '.', 'coincide', 'creation', 'special', 'unit', 'within', 'taskforce', 'track', 'spend', 'least', '10', 'serve', 'former', 'squad', 'member', '.', 'corruption', 'taskforce', ',', 'codenamed', 'ceja', ',', 'check', 'tax', 'record', 'financial', 'statement', 'bid', 'establish', 'suspect', 'accrued', 'unexplained', 'wealth', 'past', 'seven', 'year', '.', 'drug', 'squad', 'detective', 'countered', 'set', 'allegation', ',', 'complain', 'ombudsman', 'internal', 'investigation', 'flawed', ',', 'biased', 'over-zealous', '.', '.'], ['queensland', 'senator', 'andrew', 'bartlett', 'launch', 'last-minutebid', 'rescue', 'australian', 'democrat', 'split', 'threaten', 'destroy', 'party', '.', 'nominations', 'party', 'leadership', 'close', 'wednesday', 'night', ',', 'senator', 'bartlett', 'meet', 'last', 'night', 'deputy', 'leader', 'aden', 'ridgeway', 'offer', 'place', 'unity', 'ticket', 'set', 'reform', 'process', 'begin', 'heal', 'party', \"'s\", 'wound', '.', 'party', 'source', 'say', 'senator', 'ridgeway', ',', 'turn', 'former', 'leader', 'natasha', 'stott', 'despoja', ',', 'still', 'expect', 'contest', 'leadership', 'one', 'two', 'supporter', ':', 'senator', 'bartlett', 'brian', 'greig', ',', 'install', 'interim', 'leader', 'party', \"'s\", 'executive', 'last', 'thursday', '.', '.'], ['woman', 'appoint', 'head', 'independent', 'school', ',', 'thwarting', 'effort', 'show', 'woman', 'good', 'leader', ',', 'accord', 'victorian', 'independent', 'education', 'union', '.', 'although', 'make', 'two', '-thirds', 'teach', 'staff', ',', 'woman', 'hold', 'one', '-', 'third', 'principal', 'position', ',', 'union', \"'s\", 'general', 'secretary', ',', 'tony', 'keenan', ',', 'say', '.', 'believe', 'woman', 'reluctant', 'become', 'principals', 'long', 'hour', 'nature', 'work', '.', 'case', 'shut', 'top', 'position', 'perception', 'ability', 'lead', 'provide', 'discipline', '.', '.'], ['bush', 'administration', 'draw', 'plan', 'escalate', 'war', 'word', 'iraq', ',', 'new', 'campaigns', 'step', 'pressure', 'baghdad', 'rally', 'world', 'opinion', 'behind', 'us', 'drive', 'oust', 'president', 'saddam', 'hussein', '.', 'week', ',', 'state', 'department', 'begin', 'mobilising', 'iraqi', 'across', 'north', 'america', ',', 'europe', 'arab', 'world', ',', 'training', 'appear', 'talk', 'show', ',', 'write', 'opinion', 'article', 'give', 'speech', 'reason', 'end', 'president', 'saddam', \"'s\", 'rule', '.', '.'], ['beijing', 'abruptly', 'withdraw', 'new', 'car', 'registration', 'system', 'driver', 'demonstrate', '\"', 'unhealthy', 'fixation', '\"', 'symbol', 'western', 'military', 'industrial', 'strength', '-', 'fbi', '007', '.', 'senior', 'official', 'infuriated', 'popular', 'demonstration', 'interest', 'american', 'institution', 'fbi', '.', 'particularly', 'galling', 'one', \"man's\", 'choice', 'tmd', ',', 'stand', 'theatre', 'missile', 'defence', ',', 'us', '-', 'design', 'missile', 'system', 'regularly', 'vilified', 'chinese', 'propaganda', 'channel', '.', '.'], ['united', 'nation', 'world', 'food', 'program', 'estimate', '14', 'million', 'people', 'seven', 'country', '-', 'malawi', ',', 'mozambique', ',', 'zambia', ',', 'angola', ',', 'swaziland', ',', 'lesotho', 'zimbabwe', '-', 'face', 'death', 'starvation', 'unless', 'massive', 'international', 'response', '.', 'malawi', ',', 'many', '10000', 'people', 'may', 'already', 'die', '.', 'sign', 'malnutrition', '-', 'swollen', 'stomach', ',', 'stick', '-', 'thin', 'arm', ',', 'light', '-', 'coloured', 'hair', '-', 'everywhere', '.', '.'], ['malawi', ',', 'country', 'region', ',', 'aids', 'make', 'effect', 'famine', 'much', 'bad', '.', 'overall', 'hiv', 'infection', 'rate', 'malawi', '19', 'per', 'cent', ',', 'area', '35', 'percent', 'people', 'infect', '.', 'significant', 'proportion', 'young', 'adult', 'population', 'sick', 'productive', 'work', '.', 'malnutrition', 'cause', 'people', 'succumb', 'disease', 'much', 'quickly', 'west', ',', 'hunger', 'force', 'woman', 'prostitution', 'order', 'feed', 'family', ',', 'make', 'vulnerable', 'contracting', 'disease', '.', 'life', 'expectancy', 'reduce', '40', 'year', '.', '.'], ['united', 'nation', 'determine', 'showpiece', 'environment', 'summit', '-', 'big', 'conference', 'world', 'ever', 'witnessed', '-', 'staged', 'africa', '.', 'venue', ',', 'however', ',', 'could', 'remove', 'grim', 'reality', 'life', 'rest', 'africa', '.', 'johannesburg', \"'s\", 'exclusive', 'formerly', 'whites', '-only', 'suburb', 'sandton', 'wealthiest', 'neighbourhood', 'continent', '.', 'kilometre', 'sandton', 'begin', 'sprawling', 'alexandra', 'township', ',', 'nearly', 'million', 'people', 'live', 'squalor', '.', 'organisers', 'conference', ',', 'begin', 'today', ',', 'seem', 'determine', 'two', 'world', 'keep', 'far', 'apart', 'possible', '.', 'tight', 'security', 'surround', 'sandton', \"'s\", 'convention', 'centre', 'five-star', 'hotel', ',', 'world', 'leader', 'debate', 'poverty', ',', 'environment', 'sustainable', 'development', 'enjoy', 'lavish', 'hospitality', '.', '.'], ['iraqi', 'capital', 'agog', 'violent', 'death', 'one', 'world', \"'s\", 'notorious', 'terrorist', ',', 'least', 'palestinian', 'diplomat', \"'s\", 'worry', 'disposal', 'abu', 'nidal', \"'s\", 'body', ',', 'lay', 'slab', 'undisclosed', 'baghdad', 'morgue', '.', 'abu', 'nidal', \"'s\", 'fatah', 'revolutionary', 'council', 'hold', 'responsible', 'death', 'injury', 'almost', '1000', 'people', '20', 'country', 'across', 'europe', 'middle', 'east', 'three', 'decade', 'since', 'fall', 'yass', 'arafat', 'abu', 'nidal', 'see', 'arafat', \"'s\", 'willingness', 'accommodate', 'israel', 'palestinian', 'struggle', '.'], ['federal', 'government', 'say', 'change', 'announce', 'today', 'work', 'dole', 'scheme', 'benefit', 'participant', 'taxpayer', '.', 'federal', 'employment', 'service', 'minister', 'mal', 'brough', 'say', 'july', '1', 'take', 'part', 'work', 'dole', 'able', 'perform', 'extra', 'hour', 'complete', 'mutual', 'obligation', 'quickly', 'access', 'training', 'credits', '.', '.'], ['biowarfare', 'expert', 'scrutiny', 'anthrax', 'attack', 'declare', ',', '\"', 'anthrax', 'killer', ',', '\"', 'lash', 'today', 'attorney', 'general', 'john', 'ashcroft', 'call', '\"', 'person', 'interest', '\"', 'investigation', '.', 'second', 'time', 'two', 'week', ',', 'scientist', 'go', 'throng', 'reporter', 'outside', 'lawyer', \"'s\", 'office', 'profess', 'innocence', 'decry', 'attention', 'law', 'enforcers', 'contends', 'destroy', 'life', '.', '.'], ['china', 'say', 'sunday', 'issue', 'new', 'regulation', 'control', 'export', 'missile', 'technology', ',', 'take', 'step', 'ease', 'u.s.', 'concern', 'transfer', 'sensitive', 'equipment', 'middle', 'east', 'country', ',', 'particularly', 'iran', '.', 'however', ',', 'new', 'rule', 'apparently', 'ban', 'outright', 'transfer', 'specific', 'item', '-', 'something', 'washington', 'long', 'urge', 'beijing', '.', '.'], ['nigerian', 'president', 'olusegun', 'obasanjo', 'say', 'weep', 'single', 'mother', 'sentenced', 'death', 'stoning', 'child', 'wedlock', 'kill', ',', 'add', 'faith', 'court', 'system', 'overturn', 'sentence', '.', 'obasanjo', \"'s\", 'comment', 'late', 'saturday', 'appear', 'confirm', 'would', 'intervene', 'directly', 'case', ',', 'despite', 'international', 'outcry', '.', '.'], ['islamic', 'high', 'court', 'northern', 'nigeria', 'reject', 'appeal', 'today', 'single', 'mother', 'sentenced', 'stoned', 'death', 'sex', 'wedlock', '.', 'clutching', 'baby', 'daughter', ',', 'amina', 'lawal', 'burst', 'tear', 'judge', 'deliver', 'ruling', '.', 'lawal', ',', '30', ',', 'first', 'sentenced', 'march', 'give', 'birth', 'daughter', 'nine', 'month', 'divorcing', '.', '.'], ['2300', 'allegedly', 'unregistered', 'missile', 'warheads', 'come', 'store', 'canadian', 'businessman', \"'s\", 'anti-terrorism', 'training', 'facility', 'new', 'mexico', '?', 'u.s.', 'canadian', 'official', 'still', 'try', 'figure', ',', 'one', 'security', 'expert', 'say', 'mystery', '\"', 'chill', '\"', 'one', '.', 'david', 'hudak', ',', '41', ',', 'arrest', 'united', 'state', 'week', 'ago', ',', 'accord', 'court', 'document', ',', 'agent', 'search', 'property', 'find', 'warheads', 'store', 'crates', 'mark', '\"', 'charge', 'demolition', '.', '\"', '.'], ['saudi', 'interior', 'ministry', 'sunday', 'confirm', 'hold', '21', '-', 'year-', 'old', 'saudi', 'man', 'fbi', 'seek', 'allege', 'link', 'sept.', '11', 'hijacker', '.', 'authority', 'interrogating', 'saud', 'abdulaziz', 'saud', 'al', '-', 'rasheed', '\"', 'prove', 'connect', 'terrorism', ',', 'refer', 'sharia', '(', 'islamic', ')', 'court', ',', '\"', 'official', 'saudi', 'press', 'agency', 'quote', 'unidentified', 'ministry', 'official', 'say', '.', '.'], ['sri', 'lanka', \"'s\", 'government', 'lift', 'four-year', 'ban', 'tamil', 'tiger', 'rebel', 'sept.', '6', ',', 'pave', 'way', 'peace', 'talk', 'insurgent', 'schedule', 'late', 'month', 'thailand', ',', 'government', 'minister', 'say', 'saturday', '.', '\"', 'lift', 'ban', 'promise', ',', '\"', 'minister', 'rehabilitation', 'jayalath', 'jayawardena', 'tell', 'associated', 'press', '.', 'lift', 'ban', 'one', 'key', 'rebel', 'condition', 'resuming', 'peace', 'negotiation', 'government', 'hiatus', 'seven', 'year', '.', '.'], ['man', 'accuse', 'make', 'hidden-camera', 'footage', 'skirt', 'woman', 'also', 'make', 'child', 'pornography', 'bad', 'kind', ',', 'feature', 'rape', 'child', 'young', '6', ',', 'police', 'say', 'friday', '.', 'late', 'allegation', 'suggest', \"'s\", 'nothing', 'humorous', 'voyeurs', 'may', 'perceive', 'make', 'secret', 'video', 'joke', ',', 'staff-insp', '.', 'gary', 'ellis', 'say', '.', '\"', 'approximately', '20', 'per', 'cent', 'voyeurs', 'also', 'commit', 'sexual', 'assault', 'rape', ',', '\"', 'ellis', 'say', ',', 'read', 'recently', 'release', 'federal', 'government', 'report', 'criminal', 'voyeurism', '.', '.'], ['police', 'combing', 'videotapes', 'try', 'spot', 'gunman', 'dress', 'black', 'shot', '30', '-', 'year', '-', 'old', 'man', 'death', 'downtown', 'massage', 'parlour', '.', 'victim', 'hit', 'stomach', 'upper', 'body', 'die', '3', '1/2', 'hour', 'late', 'hospital', '.', 'woman', 'hurt', '.', 'police', 'urge', 'business', 'owner', 'turn', 'security', '-', 'camera', 'videotapes', 'might', 'record', 'people', 'street', 'time', '.', 'several', 'video', 'review', '.', '.'], ['federal', 'government', 'regret', 'action', '12', 'month', 'tampa', 'asylum', 'seeker', 'crisis', ',', 'small', 'business', 'minister', 'joe', 'hockey', 'say', 'today', '.', 'mr', 'hockey', 'say', 'government', 'embarrassed', 'tampa', 'issue', ',', 'begin', 'august', '27', 'last', 'year', 'captain', 'norwegian', 'cargo', 'ship', 'rescue', '400', 'asylum', 'seeker', 'indonesian', 'ferry', 'north', 'christmas', 'island', '.', '.'], ['least', 'three', 'democrat', 'consider', 'split', 'party', 'no-one', 'yet', 'nominate', 'contest', 'leadership', '.', 'three', '\"', 'gang', 'four', '\"', 'senators', 'ousted', 'natasha', 'stott', 'despoja', 'leadership', 'consider', 'form', 'new', '\"', 'progressive', 'centre', '\"', 'party', 'fallout', 'last', 'week', \"'s\", 'turmoil', '.', 'would', 'leave', 'democrat', 'rump', 'three', 'four', 'member', '.', 'west', 'australian', 'senator', 'andrew', 'murray', 'say', 'yesterday', 'unless', 'democrat', 'leave', 'wing', 'give', 'ground', 'party', 'would', 'split', '.', '.'], ['young', 'humpback', 'whale', 'remain', 'tangled', 'shark', 'net', 'gold', 'coast', 'yesterday', ',', 'despite', 'valiant', 'effort', 'marine', 'rescuer', '.', 'head', 'snared', 'net', 'anchor', 'rope', 'wrap', 'around', 'tail', ',', 'stricken', 'whale', 'still', 'swim', 'hope', 'survival', 'fade', '.', 'second', 'rescue', 'attempt', 'plan', 'dawn', 'today', 'rescuer', 'braved', 'heavy', 'sea', ',', 'strong', 'wind', 'drive', 'rain', 'try', 'free', 'whale', '.', '.'], ['prince', 'william', 'tell', 'friend', 'mother', 'right', 'along', 'suspect', 'former', 'protection', 'officer', 'spying', 'want', 'detective', 'intruding', 'privacy', '.', 'william', 'prince', 'harry', 'devastated', 'treachery', 'ken', 'wharfe', ',', 'look', 'surrogate', 'father', ',', 'refuse', 'talk', 'detective', '.', '.'], ['spectre', 'osama', 'bin', 'laden', 'rise', 'today', ',', 'urging', 'afghans', 'launch', 'new', 'jihad', ',', 'holy', 'war', ',', 'predict', 'fall', 'united', 'state', ',', 'hand-written', '\"', 'letter', '\"', 'post', 'islamic', 'website', '.', 'hard', 'proof', 'scruffy', 'missive', 'genuine', ',', 'islamonline', '.', 'net', 'say', 'receive', 'correspondent', 'jalalabad', ',', 'eastern', 'afghanistan', ',', 'afghan', 'source', 'ask', 'remain', 'anonymous', '.', 'source', 'claim', '\"', 'recent', 'letter', '\"', 'world', \"'s\", 'want', 'man', '.', '.'], ['johannesburg', 'earth', 'summit', 'set', 'get', 'way', 'promise', 'leader', 'take', 'action', 'environment', ',', 'debt', 'poverty', '.', 'south', 'african', 'president', 'thabo', 'mbeki', ',', 'speak', 'open', 'ceremony', ',', 'say', ':', '\"', 'johannesburg', 'africa', 'must', 'emerge', 'something', 'take', 'world', 'forward', '.', '\"', 'absence', 'us', 'president', 'george', 'w', 'bush', 'threaten', 'overshadow', 'summit', '.', '.'], ['robert', 'mugabe', 'strengthen', 'hold', 'zimbabwean', 'government', 'yesterday', 'retaining', 'combative', 'hardliner', 'minister', 'cabinet', 'shuffle', 'offer', 'little', 'hope', 'moderation', 'land', 'seizure', 'policy', 'keep', 'zimbabwe', 'crisis', 'bring', 'international', 'condemnation', '.', '.'], ['dress', 'black', 'disguise', 'identities', 'bandannas', 'sunglass', '.', 'logo', 'image', 'southern', 'cross', 'constellation', ',', 'superimposed', 'pair', 'cross', 'boomerangs', ',', 'resemble', 'swastika', '.', 'blackshirts', 'former', 'husband', 'aggrieved', 'treatment', 'hand', 'ex-wives', 'court', ',', 'regard', 'vanguard', '\"', \"men's\", 'rights', '\"', 'movement', 'australia', 'say', 'action', 'remember', 'mark', 'turn', '-', 'point', 'history', '.', '.'], ['real', 'level', 'world', 'inequality', 'environmental', 'degradation', 'may', 'far', 'bad', 'official', 'estimate', ',', 'accord', 'leaked', 'document', 'prepare', 'world', \"'s\", 'rich', 'country', 'see', 'guardian', '.', 'include', 'new', 'estimate', 'world', 'lose', 'almost', '10', '%', 'forests', 'past', '10', 'year', ';', 'carbon', 'dioxide', 'emission', 'lead', 'global', 'warming', 'expect', 'rise', '33', '%', 'rich', 'country', '100', '%', 'rest', 'world', 'next', '18', 'year', ';', '30', '%', 'fresh', 'water', 'need', '2020', '.', '.'], ['researcher', 'conduct', 'elaborate', 'wild', 'goose', 'chase', 'history', 'digesting', 'news', 'bird', 'track', '4500', 'mile', 'cook', '.', 'kerry', ',', 'irish', 'light', '-', 'bellied', 'brent', 'goose', ',', 'one', 'six', 'bird', 'tagged', 'northern', 'ireland', 'may', 'researcher', 'monitoring', 'species', \"'\", 'remarkable', 'migration', '.', 'last', 'week', ',', 'however', ',', 'find', 'dead', 'inuit', 'hunter', \"'s\", 'freezer', 'canada', ',', 'still', 'wear', '3000', 'satelite', 'track', 'device', '.', 'kerry', 'discover', 'researcher', 'remote', 'cornwallis', 'island', '.', 'pick', 'signal', 'decide', 'try', 'find', '.', '.'], ['russia', 'defend', 'u.s.', 'criticism', 'economic', 'tie', 'country', 'like', 'iraq', ',', 'say', 'attempt', 'mix', 'business', 'ideology', 'misguided', '.', '\"', 'mixing', 'ideology', 'economic', 'tie', ',', 'characteristic', 'cold', 'war', 'russia', 'united', 'state', 'work', 'end', ',', 'thing', 'past', ',', '\"', 'russian', 'foreign', 'ministry', 'spokesman', 'boris', 'malakhov', 'say', 'saturday', ',', 'reacting', 'u.s.', 'defense', 'secretary', 'donald', 'rumsfeld', \"'s\", 'statement', 'moscow', \"'s\", 'economic', 'relationship', 'country', 'send', 'negative', 'signal', '.', '.'], ['pope', 'john', 'paul', 'ii', 'urge', 'delegates', 'major', 'u.n.', 'summit', 'sustainable', 'growth', 'sunday', 'pursue', 'development', 'protect', 'environment', 'social', 'justice', '.', 'comment', 'tourist', 'faithful', 'summer', 'residence', 'southeast', 'rome', ',', 'pope', 'say', 'god', 'put', 'human', 'earth', 'administrators', 'land', ',', '\"', 'cultivate', 'take', 'care', '.', '\"', '\"', 'world', 'ever', 'interdependent', ',', 'peace', ',', 'justice', 'safekeeping', 'creation', 'cannot', 'fruit', 'joint', 'commitment', 'pursue', 'common', 'good', ',', '\"', 'john', 'paul', 'say', '.', '.'], ['russian', 'defense', 'minister', 'say', 'resident', 'feel', 'threaten', 'grow', 'number', 'chinese', 'worker', 'seek', 'employment', 'country', \"'s\", 'sparsely', 'populate', 'far', 'eastern', 'siberian', 'region', '.', 'exact', 'figure', 'number', 'chinese', 'work', 'russia', ',', 'estimate', 'range', '200000', 'many', '5', 'million', '.', 'russian', 'far', 'east', ',', 'arrive', 'legitimate', 'work', 'visa', 'seasonal', 'work', 'russia', \"'s\", 'low-tech', ',', 'labor-intensive', 'farm', '.', '.'], ['australian', 'spy', 'listen', 'conversation', 'norway', \"'s\", 'ambassador', 'foreign', 'office', 'tampa', 'crisis', ',', 'soon', 'publish', 'book', 'reveal', '.', 'phone', 'call', 'tapped', 'defence', 'signals', 'directorate', 'norwegian', 'ambassador', 'ove', 'thorsheim', 'visit', 'freighter', 'stand-off', '.', 'book', ',', 'tampa', ',', 'publish', 'norway', 'october', ',', 'recounts', 'event', 'trigger', 'australia', \"'s\", 'pacific', 'solution', 'transform', 'tampa', 'captain', 'arne', 'rinnan', 'homeland', 'hero', '.', '.'], ['batasuna', ',', 'political', 'party', 'campaigns', 'independent', 'basque', 'state', ',', 'face', 'double', 'blow', 'today', ':', 'spanish', 'parliament', 'expect', 'vote', 'overwhelmingly', 'favour', 'banning', 'radical', 'group', ',', 'senior', 'investigative', 'judge', 'poise', 'suspend', 'batasuna', \"'s\", 'activity', 'grounds', 'benefit', 'eta', ',', 'outlawed', 'basque', 'separatist', 'group', '.', '.'], ['river', 'elbe', 'surged', 'all-time', 'record', 'high', 'friday', ',', 'flooding', 'district', 'historic', 'city', 'dresden', 'authority', 'scramble', 'evacuate', 'ten', 'thousand', 'resident', 'bad', 'flooding', 'hit', 'central', 'europe', 'memory', '.', 'czech', 'republic', ',', 'authority', 'count', 'cost', 'massive', 'flooding', 'people', 'return', 'home', 'vlava', 'river', 'receded', ',', 'revealing', 'full', 'extent', 'damage', 'life', 'landmarks', '.', '.'], ['european', 'parliament', 'spoiling', 'fight', 'israel', '.', 'vote', 'review', 'eu', \"'s\", 'diplomatic', 'link', 'jewish', 'state', ',', 'impose', 'arm', 'embargo', 'threaten', 'wide', 'trade', 'sanction', '.', 'many', 'mep', 'want', 'go', 'dispatch', 'european', 'military', 'force', 'region', 'order', '\"', 'protect', 'palestinian', 'people', '\"', '.', '.'], ['australia', \"'s\", 'commonwealth', 'bank', 'wednesday', 'say', 'plan', 'cut', '1000', 'job', 'even', 'report', 'profit', 'rise', '11', 'percent', 'last', 'fiscal', 'year', '.', 'worker', 'react', 'angrily', 'plan', 'cut', ',', 'australia', \"'s\", 'second', 'large', 'bank', 'say', 'design', 'control', 'cost', '.', 'cut', 'take', 'effect', 'financial', 'year', '.', 'bank', 'report', 'net', 'profit', '2.66', 'billion', 'australian', 'dollar', '(', '$', '1.4', 'billion', ')', 'year', 'june', '30', ',', '2.4', 'billion', 'australian', 'dollar', 'previous', 'year', '.', '.'], ['labor', 'need', 'distinguish', 'government', 'issue', 'asylum', 'seeker', ',', 'greens', 'leader', 'bob', 'brown', 'say', '.', 'senate', 'colleague', 'kerry', 'nettle', 'intend', 'move', 'motion', 'today', '-', 'first', 'anniversary', 'tampa', 'crisis', '-', 'condemn', 'government', 'refugee', 'policy', 'call', 'end', 'mandatory', 'detention', '.', '\"', 'greens', 'want', 'bring', 'government', 'book', 'serial', 'breach', 'international', 'obligation', 'far', 'asylum', 'seeker', 'country', 'concerned', ',', '\"', 'senator', 'brown', 'say', 'today', '.', '.']]\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "print(normalized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(td_matrix):\n",
    "    \"\"\" Weighs a term-document matrix of raw counts with tf-idf scheme\n",
    "    \n",
    "    this function takes in a term-document matrix as a numpy array, \n",
    "    and weights the scores with the tf-idf algorithm described above.\n",
    "    idf values are modified with log_10\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    td_matrix : numpy array \n",
    "        a matrix where columns are songs and \n",
    "        rows are word counts in a song\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tf_idf_matrix : numpy array \n",
    "        a matrix where columns are songs and \n",
    "        rows are word tf-idf values in a song\n",
    "        \n",
    "    idf_vector : numpy array of shape (vocabulary-size, 1)\n",
    "        a vector of idf values for words in the collection. the shape is (vocabulary-size, 1)\n",
    "        this vector will be used to weight new query documents\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    idf_vector = []\n",
    "    for row in td_matrix:\n",
    "        nonzeros = np.count_nonzero(row)\n",
    "        documents = len(row)\n",
    "        if nonzeros > 0:\n",
    "            idf = np.log10(documents/nonzeros)\n",
    "        else:\n",
    "            idf = 0\n",
    "        idf_vector.append(idf)\n",
    "    \n",
    "    idf_vector = np.array(idf_vector)\n",
    "    idf_vector = idf_vector.reshape((len(idf_vector), 1))\n",
    "    tf_idf_matrix = idf_vector * td_matrix\n",
    "    \n",
    "    return tf_idf_matrix, idf_vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_term_doc_matrix(docs_normalized):\n",
    "    \"\"\" Constructs a frequency term-document matrix\n",
    "    \n",
    "    this function takes in a list of songs and returns a term-document matrix\n",
    "    the rows are lemma types, the columns are songs \n",
    "    the rows should be sorted alphabetically\n",
    "    the order of the columns should be preserved as it's given in docs_normalized\n",
    "    the cell values are a number of times a lemma was seen in a song\n",
    "    the value should be zero, if a lemma is absent from a song\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    docs_normalized : a list of lists of strings [['a','a','b'], ['a','b','c']]\n",
    "        a list of songs represented as a list of lemmas\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matrix : numpy array\n",
    "        a matrix where columns are songs and rows are lemma types,\n",
    "        the cells of the matrix contain lemma counts in a song,\n",
    "        the lemmas for rows are sorted alphabetically\n",
    "        for the example above it will be:\n",
    "            np.array([[2,1],\n",
    "                      [1,1],\n",
    "                      [0,1]])\n",
    "        \n",
    "    sorted_vocab : list of strings\n",
    "        a list of all the lemma types used in all songs (the rows of our matrix)\n",
    "        the words should be strings sorted alphabetically\n",
    "        for the example above it should be ['a','b','c']\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. create one ordered list of all terms\n",
    "    sorted_vocab = []\n",
    "    for song in docs_normalized:\n",
    "        sorted_vocab += song\n",
    "    if sorted_vocab != None:\n",
    "        sorted_vocab = list(set(sorted_vocab))\n",
    "        sorted_vocab.sort() \n",
    "    \n",
    "    # 2. count the number of occurences of each term in each song\n",
    "    # 2.2. add to list of list\n",
    "    matrix = []\n",
    "    for term in sorted_vocab:\n",
    "        term_counts = []\n",
    "        for song in docs_normalized:\n",
    "            occurences = song.count(term)\n",
    "            term_counts.append(occurences)\n",
    "        matrix.append(term_counts)\n",
    "    \n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    return matrix, sorted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix, sorted_vocab = create_term_doc_matrix(normalized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1391, 50)\n"
     ]
    }
   ],
   "source": [
    "print(term_doc_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(td_matrix):\n",
    "    \"\"\" Weighs a term-document matrix of raw counts with tf-idf scheme\n",
    "    \n",
    "    this function takes in a term-document matrix as a numpy array, \n",
    "    and weights the scores with the tf-idf algorithm described above.\n",
    "    idf values are modified with log_10\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    td_matrix : numpy array \n",
    "        a matrix where columns are songs and \n",
    "        rows are word counts in a song\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tf_idf_matrix : numpy array \n",
    "        a matrix where columns are songs and \n",
    "        rows are word tf-idf values in a song\n",
    "        \n",
    "    idf_vector : numpy array of shape (vocabulary-size, 1)\n",
    "        a vector of idf values for words in the collection. the shape is (vocabulary-size, 1)\n",
    "        this vector will be used to weight new query documents\n",
    "    \"\"\"\n",
    "    idf_vector = []\n",
    "    for row in td_matrix:\n",
    "        nonzeros = np.count_nonzero(row)\n",
    "        documents = len(row)\n",
    "        if nonzeros > 0:\n",
    "            idf = np.log10(documents/nonzeros)\n",
    "        else:\n",
    "            idf = 0\n",
    "        idf_vector.append(idf)\n",
    "    \n",
    "    idf_vector = np.array(idf_vector)\n",
    "    idf_vector = idf_vector.reshape((len(idf_vector), 1))\n",
    "    tf_idf_matrix = idf_vector * td_matrix\n",
    "    \n",
    "    return tf_idf_matrix, idf_vector   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix, idf_vector = tf_idf(term_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1391, 50)\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1391, 50)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(tf_idf_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 2.13781479e-02 4.72442066e-03 2.98296072e-02\n",
      " 1.59332365e-03 1.36881180e-02 1.72153297e-02 2.27744278e-02\n",
      " 6.69741566e-02 3.92486390e-03 3.45599622e-03 1.84738436e-03\n",
      " 1.77662790e-02 3.84084772e-01 4.82750390e-02 1.95348520e-03\n",
      " 3.23847472e-03 2.03652701e-02 1.47581451e-02 1.82154977e-02\n",
      " 7.73358714e-03 7.21878314e-07 1.93592903e-03 1.32865111e-02\n",
      " 2.21279922e-03 1.71801996e-02 1.76944690e-03 3.24662851e-03\n",
      " 1.00893892e-02 1.57550568e-03 5.02011734e-03 1.27807306e-02\n",
      " 1.79229233e-01 8.82599272e-05 7.65711903e-05 1.95474355e-03\n",
      " 1.93600134e-02 2.27611466e-02 1.83126119e-02 1.37678122e-03\n",
      " 2.76650369e-03 3.44635866e-03 1.40324171e-04 3.50182704e-03\n",
      " 1.03476441e-02 4.06431049e-02 8.62332080e-05 2.14074821e-03\n",
      " 3.35951525e-02 6.69528123e-02]\n"
     ]
    }
   ],
   "source": [
    "print(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.13781479e-02 1.00000000e+00 7.14311070e-03 1.97872424e-02\n",
      " 4.86577468e-03 7.12496677e-03 9.91989641e-02 1.40579191e-02\n",
      " 1.97446385e-02 6.89966106e-03 3.69667137e-02 5.08562291e-03\n",
      " 6.99804289e-03 9.59810692e-03 2.18703851e-03 8.00589238e-03\n",
      " 6.08308715e-03 2.94489900e-02 4.73513675e-02 1.84346628e-02\n",
      " 3.36389579e-02 1.64930833e-02 8.29278060e-03 2.23322244e-03\n",
      " 1.89262575e-03 8.79847042e-03 7.86197728e-03 6.64036234e-03\n",
      " 2.65797727e-02 5.23253759e-02 1.71504699e-02 4.28433400e-02\n",
      " 7.34790090e-03 6.22605164e-03 4.26442771e-05 1.84420128e-02\n",
      " 4.37043202e-03 7.45375972e-07 1.40573214e-02 2.28396767e-02\n",
      " 1.23007146e-02 6.18042117e-03 4.15132757e-02 1.53574194e-02\n",
      " 8.92836443e-03 1.88414593e-02 2.51387025e-02 5.32193151e-03\n",
      " 1.25730666e-01 6.17773625e-03]\n"
     ]
    }
   ],
   "source": [
    "print(similarities[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225\n",
      "1225\n"
     ]
    }
   ],
   "source": [
    "human_evaluation_data = pd.read_csv(\"Data/AverageSimilarities_fixed.csv\")\n",
    "tf_idf_similarities =similarities[human_evaluation_data.Document_1-1, human_evaluation_data.Document_2-1]\n",
    "print(len(tf_idf_similarities))\n",
    "print(len(human_evaluation_data.Similarity_avg_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_evaluation_data[\"Similarity_tf_idf\"] = tf_idf_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_1</th>\n",
       "      <th>Document_2</th>\n",
       "      <th>Similarity_avg</th>\n",
       "      <th>Similarity_avg_normalized</th>\n",
       "      <th>Similarity_word2vec</th>\n",
       "      <th>Similarity_doc2vec</th>\n",
       "      <th>Similarity_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.387408</td>\n",
       "      <td>0.021084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.539679</td>\n",
       "      <td>0.241664</td>\n",
       "      <td>0.004666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.274009</td>\n",
       "      <td>0.169370</td>\n",
       "      <td>0.028945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.392186</td>\n",
       "      <td>0.274045</td>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.252070</td>\n",
       "      <td>0.385343</td>\n",
       "      <td>0.013378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_1  Document_2  Similarity_avg  Similarity_avg_normalized  \\\n",
       "0           1           2             1.5                      0.125   \n",
       "1           1           3             1.2                      0.050   \n",
       "2           1           4             1.0                      0.000   \n",
       "3           1           5             1.5                      0.125   \n",
       "4           1           6             2.5                      0.375   \n",
       "\n",
       "   Similarity_word2vec  Similarity_doc2vec  Similarity_tf_idf  \n",
       "0             0.180149            0.387408           0.021084  \n",
       "1             0.539679            0.241664           0.004666  \n",
       "2             0.274009            0.169370           0.028945  \n",
       "3             0.392186            0.274045           0.001599  \n",
       "4             0.252070            0.385343           0.013378  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_evaluation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_evaluation_data.to_csv('Data/AverageSimilarities_fixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.56675568],\n",
       "       [0.56675568, 1.        ]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(human_evaluation_data.Similarity_avg_normalized, tf_idf_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.44519815],\n",
       "       [0.44519815, 1.        ]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(human_evaluation_data.Similarity_avg_normalized, human_evaluation_data.Similarity_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46886663],\n",
       "       [0.46886663, 1.        ]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(human_evaluation_data.Similarity_avg_normalized, human_evaluation_data.Similarity_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46886663],\n",
       "       [0.46886663, 1.        ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(human_evaluation_data.Similarity_avg, human_evaluation_data.Similarity_word2vec)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
