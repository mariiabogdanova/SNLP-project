{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIMPORTANT!\\nRequires Python 2\\none set up option here:\\nhttps://www.dev2qa.com/how-to-run-python-2-code-in-jupyter-notebook/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "IMPORTANT!\n",
    "Requires Python 2\n",
    "one set up option here:\n",
    "https://www.dev2qa.com/how-to-run-python-2-code-in-jupyter-notebook/\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity: doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mariiabogdanova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_1</th>\n",
       "      <th>Document_2</th>\n",
       "      <th>Similarity_avg</th>\n",
       "      <th>Similarity_avg_normalized</th>\n",
       "      <th>Similarity_word2vec</th>\n",
       "      <th>Similarity_doc2vec</th>\n",
       "      <th>Similarity_tf_idf</th>\n",
       "      <th>Similarities_SBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.546141</td>\n",
       "      <td>0.412920</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>0.226575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.756276</td>\n",
       "      <td>0.224046</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.249689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.602858</td>\n",
       "      <td>0.201932</td>\n",
       "      <td>0.028945</td>\n",
       "      <td>0.231258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.645505</td>\n",
       "      <td>0.225909</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.160115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.640220</td>\n",
       "      <td>0.375090</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.189578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_1  Document_2  Similarity_avg  Similarity_avg_normalized  \\\n",
       "0           1           2             1.5                      0.125   \n",
       "1           1           3             1.2                      0.050   \n",
       "2           1           4             1.0                      0.000   \n",
       "3           1           5             1.5                      0.125   \n",
       "4           1           6             2.5                      0.375   \n",
       "\n",
       "   Similarity_word2vec  Similarity_doc2vec  Similarity_tf_idf  \\\n",
       "0             0.546141            0.412920           0.021084   \n",
       "1             0.756276            0.224046           0.004666   \n",
       "2             0.602858            0.201932           0.028945   \n",
       "3             0.645505            0.225909           0.001599   \n",
       "4             0.640220            0.375090           0.013378   \n",
       "\n",
       "   Similarities_SBERT  \n",
       "0            0.226575  \n",
       "1            0.249689  \n",
       "2            0.231258  \n",
       "3            0.160115  \n",
       "4            0.189578  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_evaluation_data = pd.read_csv(\"Data/AverageSimilarities_fixed.csv\")\n",
    "human_evaluation_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in range (0, 50):\n",
    "    FILENAME = \"Data/Docs/{}.txt\".format(i)\n",
    "    with open(FILENAME, 'r') as inputfile:\n",
    "        lines = inputfile.readlines()\n",
    "        for line in lines:\n",
    "            documents.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>documents_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The national executive of the strife-torn Demo...</td>\n",
       "      <td>national executive strife torn democrats last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash-strapped financial services group AMP has...</td>\n",
       "      <td>cash strapped financial services group amp she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The United States government has said it wants...</td>\n",
       "      <td>united states government said wants see presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A radical armed Islamist group with ties to Te...</td>\n",
       "      <td>radical armed islamist group ties tehran baghd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington has sharply rebuked Russia over bom...</td>\n",
       "      <td>washington sharply rebuked russia bombings geo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  The national executive of the strife-torn Demo...   \n",
       "1  Cash-strapped financial services group AMP has...   \n",
       "2  The United States government has said it wants...   \n",
       "3  A radical armed Islamist group with ties to Te...   \n",
       "4  Washington has sharply rebuked Russia over bom...   \n",
       "\n",
       "                                   documents_cleaned  \n",
       "0  national executive strife torn democrats last ...  \n",
       "1  cash strapped financial services group amp she...  \n",
       "2  united states government said wants see presid...  \n",
       "3  radical armed islamist group ties tehran baghd...  \n",
       "4  washington sharply rebuked russia bombings geo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df = pd.DataFrame(documents,columns=['documents'])\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "documents_df['documents_cleaned'] = documents_df.documents.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stopwords_list) )\n",
    "documents_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please download English Wikipedia Skip-Gram (1.4GB) download from https://github.com/jhlau/doc2vec\n",
    "model = gensim.models.doc2vec.Doc2Vec.load('enwiki_dbow/doc2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for doc1, doc2 in zip(human_evaluation_data.Document_1.values, human_evaluation_data.Document_2.values):\n",
    "\n",
    "    fisrt_text = documents_df.documents_cleaned.values[doc1-1]\n",
    "    second_text = documents_df.documents_cleaned.values[doc2-1]\n",
    "\n",
    "    vec1 = model.infer_vector(fisrt_text.split()).reshape(1, -1)\n",
    "    vec2 = model.infer_vector(second_text.split()).reshape(1, -1)\n",
    "\n",
    "    cos_distance = cosine_similarity(vec1, vec2)\n",
    "    data.append(cos_distance[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_evaluation_data['Similarity_doc2vec'] = data\n",
    "human_evaluation_data.to_csv('Data/AverageSimilarities_fixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6257019732333775"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.pearsonr(human_evaluation_data.Similarity_avg.values, data)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
